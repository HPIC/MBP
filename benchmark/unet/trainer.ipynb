{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Define Class\n",
    "from torch import Tensor\n",
    "from torch.nn.modules import Module\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import random_split, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import model\n",
    "''' Micro-Batch Streaming '''\n",
    "from mbs import MicroBatchStreaming\n",
    "\n",
    "''' Monitoring Board '''\n",
    "import wandb\n",
    "\n",
    "from conf import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(random_seed)\n",
    "\n",
    "## Setup train epochs\n",
    "epochs = 3\n",
    "\n",
    "## Setup Optimizer\n",
    "lr = 1e-4\n",
    "\n",
    "## Setup Dataloader\n",
    "carvana_mean = [0.0, 0.0, 0.0]\n",
    "carvana_std = [1.0, 1.0, 1.0]\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 6\n",
    "image_scale = 1/4\n",
    "train_val_split = 0.1\n",
    "\n",
    "## Setup  GPU\n",
    "gpu_index = 0\n",
    "gpu = torch.device(f\"cuda:{gpu_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    epoch: int, total_epoch: int,\n",
    "    device: torch.device,\n",
    "    model: Module, \n",
    "    criterion: _Loss, \n",
    "    optimizer: Optimizer, \n",
    "    dataloader: DataLoader\n",
    "):\n",
    "    loss: Tensor\n",
    "    dice: Tensor\n",
    "    losses = []\n",
    "    dataloader_len = len(dataloader)\n",
    "    model.train()\n",
    "    for idx, (inputs, masks) in enumerate(dataloader):\n",
    "        inputs: Tensor = inputs.to(device)\n",
    "        masks: Tensor = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds: Tensor = model( inputs )\n",
    "        loss, dice = criterion( preds, masks )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append( loss.item() )\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{total_epoch}][{idx+1}/{dataloader_len}]\\t\",\n",
    "        f\"train loss : {sum(losses)/len(losses):.4f}\\t\",\n",
    "        f\"input image size: {inputs.size()}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(\n",
    "    device: torch.device,\n",
    "    model: Module, \n",
    "    criterion: _Loss,\n",
    "    dataloader: DataLoader\n",
    "):\n",
    "    correct = 0.0\n",
    "    test_num = 0.0\n",
    "    test_losses = []\n",
    "    model.eval()\n",
    "    for idx, (inputs, masks) in enumerate(dataloader):\n",
    "        inputs: Tensor = inputs.to(device)\n",
    "        masks: Tensor = masks.to(device)\n",
    "\n",
    "        preds: Tensor = model( inputs )\n",
    "        loss: Tensor = criterion(preds, masks)\n",
    "\n",
    "        test_losses.append( loss.item() )\n",
    "        _, pred = preds.max(1)\n",
    "\n",
    "        equal_factor = pred.eq(masks).sum()\n",
    "        test_num += masks.nelement()\n",
    "        correct += equal_factor\n",
    "        corrects = 100 * ( correct * test_num )\n",
    "\n",
    "    print(\n",
    "        f\"\\nval loss: {sum(test_losses)/len(test_losses):.4f}\\t\",\n",
    "        f\"Accuracy: {corrects}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carvana Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  CarvanaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = \"data\",\n",
    "        image_transform: transforms = None,\n",
    "        mask_transform: transforms = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.image_path = os.path.join( root, \"train\" )\n",
    "        self.mask_path = os.path.join( root, \"train_masks\" )\n",
    "\n",
    "        self.images = os.listdir( self.image_path )\n",
    "        self.masks = os.listdir( self.mask_path )\n",
    "        assert len(self.images) == len(self.masks), \"The length does not equal!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.image_path, self.images[index])\n",
    "        mask_path = os.path.join(self.mask_path, self.images[index])\n",
    "        mask_path = mask_path.split(\".\")[0] + '_mask.gif'\n",
    "\n",
    "        image = np.array( Image.open( image_path ).convert(\"RGB\") )\n",
    "        mask = np.array( Image.open( mask_path ).convert(\"L\"), dtype=np.float32 )\n",
    "        mask[mask == 255.0] = 1.0\n",
    "\n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform( image )\n",
    "        if self.mask_transform is not None:\n",
    "            mask = self.mask_transform( mask )\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transforms for inputs and masks\n",
    "image_compose = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(carvana_mean, carvana_std),\n",
    "        transforms.Resize( ( int(1280 * image_scale), int(1918 * image_scale) ) )\n",
    "    ])\n",
    "masks_compose = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize( ( int(1280 * image_scale), int(1918 * image_scale) ) )\n",
    "    ])\n",
    "\n",
    "# Define dataset\n",
    "carvana_dataset = CarvanaDataset(\n",
    "    root='data',\n",
    "    image_transform=image_compose,\n",
    "    mask_transform=masks_compose \n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "num_val     = int( len(carvana_dataset) * train_val_split )\n",
    "num_train   = len(carvana_dataset) - num_val\n",
    "train_dataset, val_dataset =  random_split(\n",
    "    carvana_dataset,\n",
    "    [num_train, num_val],\n",
    "    generator=torch.Generator().manual_seed(random_seed)\n",
    ")\n",
    "\n",
    "# Define dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Specific Loss (Criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred: Tensor, mask: Tensor, smooth: int = 1e-5):\n",
    "    bce_output = F.binary_cross_entropy_with_logits(\n",
    "        pred, mask, reduction=\"sum\"\n",
    "    )\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * mask).sum(dim=(2,3))\n",
    "    union = pred.sum(dim=(2,3)) + mask.sum(dim=(2,3))\n",
    "    \n",
    "    # dice coefficient\n",
    "    dice = 2.0 * (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    # dice loss\n",
    "    dice_loss = 1.0 - dice\n",
    "    \n",
    "    # total loss\n",
    "    loss: Tensor = bce_output + dice_loss\n",
    "    return loss.sum(), dice.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model, Criterion, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_network_name\n",
    "\n",
    "unet = get_network_name('unet3156').to(gpu)\n",
    "# criterion = nn.BCEWithLogitsLoss().to(gpu)\n",
    "criterion = dice_loss\n",
    "optimizer = optim.Adam( unet.parameters(), lr=lr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler, WarmUP Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3][1145/1145]\t train loss : 319884.7264\t input image size: torch.Size([4, 3, 320, 479])\n",
      "\n",
      "val loss: 133810.2808\t Accuracy: 1.9082913530081444e+18%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train( epoch, epochs, gpu, unet, criterion, optimizer, train_dataloader )\n",
    "    validation( gpu, unet, criterion, val_dataloader )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b6ed9e3b2076da27cd8bbc6299d6b52e5558d895cc109777136b01451c9c698"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mbs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
